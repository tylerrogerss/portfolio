Tyler Rogers PSTATW 174 Final Project

The data used was acquired from the package tsdl. Our data initially showed a clear upward trend, with stable variance.
We performed a box cox transformation to further stabilize the variance and to make our time series more Gaussian. We then differenced at lag 12 to remove seasonality. We again differenced at lag 1 in an attempt to remove trend, but ended up with a larger variance so we kept the previous. We then fit a couple models and picked the best one. We used the models to accurately predict future car sales in Quebec.

```{r}
library(tsdl)
library(xts)
library(forecast)
library(MASS)
library(astsa)
library(UnitCircle)
library(qpcR)
```

```{r}
head(tsdl)
```


```{r}
meta_tsdl$description[[9]]
quebec.ts <- tsdl[[9]]
```

```{r}
length(quebec.ts)
training = quebec.ts[1:72]
testing = quebec.ts[73:108]
quebec_train = ts(training, start = c(1960,1), frequency = 12)
```

```{r}
plot(decompose(quebec_train))
```
There a clear upward trend between Jan 1960 to the end of the data. Also, a clear seasonal pattern is presented in the plot, as we can see the observations regularly go up and down. The variance is relatively stable across time. Therefore, this time series is not stationary.

```{r}
# Plot the data versus time.
plot(quebec_train, main = "Time Series from Year 1960 to 1968")
# Plot the data versus time index number from 1, 2, . . . n. 
plot(1:length(quebec_train),quebec_train, main =
       "Time Series from Year 1960 to 1968", type = 'l',xlab='index')
# Add regression line and mean line to the plot
index = 1: length(quebec_train)
trend <- lm(quebec_train ~ index)
abline(trend, col="red")
abline(h=mean(quebec_train) , col='blue')
```

```{r}
library(zoo)
smooth_data_5m = zoo::rollmean(quebec_train, k = 5, fill = NA)
smooth_data_12m = zoo::rollmean(quebec_train, k = 12, fill = NA)
plot(quebec_train, main = "Time Series from Year 1960 to 1968")
lines(smooth_data_5m, col='blue' )
lines(smooth_data_12m, col='red')
legend("topleft", legend=c("Original data","5-month average", "12-month average"),
       col=c("black" ,"blue", "red"), lty=1, cex=0.8)
```
By using longer time intervals, such as months, to create the average time series, we can achieve smoother data with reduced variance. The 12-month average data tends to be smoother compared to the 5-month average

```{r}
x_t = filter(quebec_train, filter = rep(1/3,3), sides = 2, method = "convolution")
plot(quebec_train, type = "l", main = "Smoothing Process")
# Plot of Smoothing Process
lines(x_t,col = "blue")

acf(quebec_train, main="ACF")
acf(x_t,na.action = na.pass, main="ACF of Smoothing Process")

```

```{r}
#Box-Cox Tranformation
t = 1:length(quebec_train)
fit = lm(quebec_train ~ t)
bcTransform = boxcox(quebec_train ~ t,plotit = TRUE)
```

The dashed vertical lines in the plot above correspond to a 95% confidence interval for the true value of λ in the Box-Cox transformation. 

The confidence interval includes λ = 0, so we can try log transformation

```{r}
lambda = bcTransform$x[which(bcTransform$y == max(bcTransform$y))]
quebec.bc = log(quebec_train)
lambda
```

```{r}
# plot the original data vs Box-Cox transformed data:
op <- par(mfrow = c(1,2))
ts.plot(quebec_train, main = "Original data", ylab = expression(X[t]))
ts.plot(quebec.bc, main = "Box-Cox tranformed data", ylab = expression(Y[t]))
```

The transformed data has a more stable variance acorss time.

```{r}
op <- par(mfrow = c(1,2))
hist(quebec_train,main = "Original data",ylab = expression(X[t]))
hist(quebec.bc,main = "Box-Cox tranformed data", ylab = expression(Y[t]))
```

the transformed data is more Gaussian than the original. Therefore, the transformed data is more appropriate than the original.

```{r}
par(op)
```


```{r}
# Calculate the sample variance and plot the acf/pacf
var(quebec_train)
var(quebec.bc)

op = par(mfrow = c(1,2))
acf(quebec.bc,lag.max = 60,main = "")
pacf(quebec.bc,lag.max = 60,main = "")
title("Box-Cox Transformed Time Series", line = -1, outer=TRUE)
```
There is a cyclical behavior in the ACF of the transformed data.
There are significant correlations with values moving proportionally every 12 lags. Therefore, we can see that the period of the seasonal component is given by s = 12.

Remove seasonal components by differencing the transformed time series 

```{r}
# Diference at lag = 12 to remove seasonal component
y1 = diff(quebec.bc, 12)
plot(y1, main = "De-seasonalized Time Series")
abline(h = 0,lty = 2)
```

After differencing to remove seasonal component, we need to assess whether we need to difference to remove trend.

```{r}
plot(1:length(y1), y1, 
     main ="De-seasonalized Time Series", type = 'l')
index = 1: length(y1)
trend <- lm(y1 ~ index)
abline(trend, col="red")
abline(h=mean(y1) , col='blue')
abline(h = 0,lty = 2)
```

the regression line is quite horizontal, meaning that we may not have trend now.

So, we plot the acf and see whether it continues to be periodic or large for large lag.

```{r}
# Re-calculate the sample variance and examine the ACF and PACF
op = par(mfrow = c(1,2))
acf(y1,lag.max = 60,main = "")
pacf(y1,lag.max = 60,main = "")
title("De-seasonalized Time Series", line = -1, outer=TRUE)
```

neither ACF nor PACF continues to be periodic or large for large lag. The ACF also decreases fast, which indicates that we may not have trend here.

We can also see a few significant ACF and PACF values of the de-seasonalized data.

First from the sample ACF plot, ACF values at lag 12(1∗s), lag 2 is significant. ACF value at lag 24 (4∗s), lag 2 is significant. 

For simplicity, we can choose Q=1 and q=1 for the SARIMA model.

Then from the sample PACF, PACF values at lag 12(1∗s), 24(2∗s), 2 and 8 are significant. Therefore, we can choose P=2 and q=2 or 8 for SARIMA model

```{r}
par(op)
```

```{r}
# Difference to remove trend component
y12 = diff(y1, 1)
ts.plot(y12,main = "De-trended/seasonalized Time Series")
abline(h = 0,lty = 2)
```

```{r}
# Re-calculate the sample variance and examine the ACF and PACF
op = par(mfrow = c(1,2))
acf(y12,lag.max = 60,main = "")
pacf(y12,lag.max = 60,main = "")
title("De-trended/seasonalized Time Series",line = -1, outer=TRUE)
```

```{r}
# keep track of the variance at each step:
# variance of transformed data
var(quebec.bc)

#variance of de-seasonalized data
var(y1)

#variance of de-trended/seasonalized data
var(y12)
```

The variance of the de-seasonalized data has the lowest variance, so we do not need to de-trend the data. De-seasonalized data is enough for further analysis.

```{r}
op = par(mfrow = c(1,2))
acf(y1,lag.max = 60,main = "")
pacf(y1,lag.max = 60,main = "")
title("De-seasonalized Time Series", line = -1, outer=TRUE)
```
• We applied one seasonal differencing so D = 1 at lag s = 12.
• The ACF shows a strong peak at h = 1s 
A good choice for the MA part could be Q=1 
• The PACF shows two strong peaks at h = 1s
A good choice for the AR part could be P = 1 or = 2.
Modeling the non-seasonal part (p , d, q): 
• The ACF seems to be tailing off. Or perhaps cuts off at lag.
good choice for the MA part could be q = 0 or q = 4 
• The PACF cuts off at lag h=1 or 2.
A good choice for the AR part could be p = 1 or p = 2.

we fit the following two models:
i. SARMA(p=1,d=0,q=0)×(P=1,D=1,Q=1)s=12
ii. SARMA(p=2,d=1,q=4)×(P=2,D=1,Q=1)s=12


Model 1:
```{r}
fit.i2 <- sarima(quebec.bc,p = 1, d = 0, q = 0,
P = 2 , D = 1, Q = 1, S = 12, details = F)
fit.i2$fit
fit.i <- sarima(y1,p = 1, d = 0, q = 0,
P = 2 , D = 1, Q = 1, S = 12, details = F)
fit.i$fit
```

From the above coefficients table, sar1, sar2, sma1 are not significant because the confidence interval of the estimated coefficient contains 0. Therefore, we should set these coefficients to 0.
```{r}
fit.i1 <- sarima(y1,p = 1, d = 0, q = 0,
P = 2 , D = 1, Q = 1, S = 12, details = F, fixed=c(NA,0,0,0,NA))
fit.i1$fit
```
model:
(1-0.1364B)(1-B)(1-B^12)X_t = Z_t
check the model stationarity/invertibility.
AR part (1 − 0.1364B): 0.1364 < 1, so the root is greater than 1. 
No MA part

```{r}
# roots of AR part
uc.check(pol_ = c(1, 0.1364), plot_output = TRUE)
```

the roots are outside the unit circle so, the model is stationary and invertible.


```{r}
#plot residuals
plot(fit.i$fit$residuals)
```

Model 2:
```{r}
fit.ii <- sarima(y12 ,p = 2, d = 1, q = 4, P = 2 , D = 1, Q = 1, S = 12, details = F)
fit.ii$fit
```
From the above coefficients table, sar2, sma1
are not significant because the confidence interval of the estimated coefficient contains 0. Therefore, we
should set these coefficients to 0.
```{r}
fit.ii1 <- sarima( xdata = prodn,p = 2, d = 1, q = 4,
P = 2 , D = 1, Q = 1, S = 12,
details = F,fixed=c(NA,NA,NA,NA,NA,NA,NA,0,0))
fit.ii1$fit
```

(1-0.0358B-0.0272B^2)(1+0.3951B^12)(1-B)(1-B^12)X_t = (1+0.2852B+0.1667B^2+0.0829B^3+0.2083B^4)Z_t

```{r}
# roots of AR part
uc.check(pol_ = c(1, -0.0358, -0.0272), plot_output = TRUE)
# roots of MA part
uc.check(pol_ = c(1, 0.2852,0.1667,0.0829,0.2083), plot_output = TRUE)
#roots for SAR part
uc.check(pol_ = c(1, 0.3951), plot_output = TRUE)

```

From the plots above, the roots are outside the unit circle so , the model is stationary and invertible.

```{r}
plot(fit.ii1$fit$residuals)
```


Model 2 is the model obtained using AICc, our ACF/PACF also suggest this model.

```{r}
res4 <- fit.ii1$fit$residuals
hist(res4,density=20,breaks=20, col="blue", xlab="", prob=TRUE,main="Histogram of res
iduals of model B")
m <- mean(res4)
std <- sqrt(var(res4))
curve( dnorm(x,m,std), add=TRUE )
plot.ts(res4,ylab= "residuals of model B",main="Residuals plot of model B")
fitt <- lm(res4 ~ as.numeric(1:length(res4)))
abline(fitt, col="red")
abline(h=mean(res4), col="blue")
qqnorm(res4,main= "Normal Q-Q Plot for Model B")
qqline(res4,col="blue")
```
No trend or obvious seasonality, we also see it seems to follow a normal distribution from the histogram and q-q plot.

```{r}
#Shapiro test for normality
shapiro.test(res4)
```
```{r}
#Box-Pierce test
Box.test(res4, lag = 10, type = c("Box-Pierce"), fitdf = 7)
```


```{r}
#Ljung-Box test
Box.test(res4, lag = 9, type = c("Ljung-Box"), fitdf = 7)
```

```{r}
#McLeod-Li test
Box.test(res4**2, lag = 9, type = c("Ljung-Box"), fitdf = 0)
```

```{r}
ar(res4, aic = TRUE, order.max = NULL, method = c("yule-walker"))
```
```{r}
acf(res4, lag.max=40,main="")
title("ACF of the residuals of Model B")
pacf(res4, lag.max=40,main="")
title("PACF of the residuals of Model B")
```
```{r}
fitB = arima(quebec.bc, order=c(0,1,1), seasonal = list(order = c(3,0,0)
, period = 12) ,fixed = c(NA, NA, 0, NA), method="ML")
op = par(mfrow = c(1,2))
pred.tr <- predict(fitB, n.ahead = 10)
U.tr= pred.tr$pred + 2*pred.tr$se
L.tr= pred.tr$pred - 2*pred.tr$se
ts.plot(quebec.bc, xlim=c(1,length(quebec.bc)+10), ylim = c(min(quebec.bc),max(U.tr)))
lines(U.tr, col="blue", lty="dashed")
lines(L.tr, col="blue", lty="dashed")
points((length(quebec.bc)+1):(length(quebec.bc)+10), pred.tr$pred, col="red")
pred.tr <- predict(fitB, n.ahead = 10)
U.tr <- pred.tr$pred + 2*pred.tr$se
L.tr <- pred.tr$pred - 2*pred.tr$se
ts.plot(quebec.bc, max(U.tr))
lines(U.tr, col="blue", lty="dashed")
lines(L.tr, col="blue", lty="dashed")
points((length(quebec.bc)+1):(length(quebec.bc)+10), pred.tr$pred, col="red")

```
Above is the forecast on the transformed data. The true values are within the confidence interval of the forecasting.



pred.orig <- (pred.tr$pred)**(1/0.18)
U= (U.tr)**(1/0.18)
L= (L.tr)**(1/0.18)
par(mfrow=c(2,1))
ts.plot(as.numeric(testing), ylim = c(0,max(U)),col="red",main="Visualization of forecasting on testing set")
lines(U, col="blue", lty="dashed")
lines(L, col="blue", lty="dashed")
points((length(training)+1):(length(training)+10), pred.orig, col="black")
ts.plot(as.numeric(testing), xlim = c(109,length(training)+10), ylim = c(200,max
(U)),col="red",main="Zoomed in visualization of forecasting on
testing set")
lines(U, col="blue", lty="dashed")
lines(L, col="blue", lty="dashed")
points((length(training)+1):(length(training)+10), pred.orig, col="black")
```

our model performs well in forecasting for future Monthly car sales in Quebec.
